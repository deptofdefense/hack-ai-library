# Hack-AI Resource Library

A collection of resources for budding AI hackers.  *Note this is an evolving resource, so feel free to contribute via a pull request*

## Background

This repository is meant to be a collection of resources and tools for anyone wanting to dive into programming their own AI or hacking existing AI systems.  

## Resources

These are publicly available resources that anyone can use or access.  These are all intended to be intro and novice friendly.  

### Workshops

 - GPT Prompt Attack: https://gpa.43z.one/
   - This is a great example game of how to carry out prompt attacks
 - GPT Crafting Game: https://gpt.43z.one/
   - A great challenge for learning how to craft specific prompts for LLMs
 - Merlin's Defense: https://mcaledonensis.blog/merlins-defense/
   - The original popular prompt attack challenge


### Programming Libraries

- LangChain: https://github.com/hwchase17/langchain
  - This is a great library for anyone wanting to make their code compatible across multiple LLMs


### Articles and Op-Eds

- Prompt Injections Explained: https://simonwillison.net/2023/May/2/prompt-injection-explained/
  - An explainer on why prompt injection attacks work, and why we're kinda stuck with them forever

### Videos

- Attacking LLM- Prompt Injection: https://www.youtube.com/watch?v=Sv5OLj2nVAQ
  - A video discussing what prompt injections are
- Accidental LLM Backdoor - Prompt Tricks: https://www.youtube.com/watch?v=h74oXb4Kk8k
  - A video walking through crafting prompt injections
- Jailbreak example: https://www.youtube.com/watch?v=S7jviw0BgKE
  - A video showing all the process and steps in crafting you're own prompt injections


### Books and White Papers

- Compromising LLMs using Indirect Prompt Injections: https://github.com/greshake/llm-security
  - A great writeup of how an attacker can use indirect prompt injections to attack systems.  




## Contacts

[AI Village](https://aivillage.org/)

[DDS](https://www.dds.mil/)
